import timeimport pickleimport argparseimport torchimport torch.optim as optimimport torchvision.transforms as transformsfrom torch.optim.lr_scheduler import ReduceLROnPlateaufrom torch.utils.data import DataLoaderfrom torch.autograd import Variablefrom utils.models import *from utils.dataset import *from utils.loss import *from utils.logger import Loggerclass DebuggerBase:def __init__(self, args):self. argsself. 10000000000self. 1000000self. 1000000self. 10000000self. 10000000000self. 1000000self. 1000000self. 10000000self. Noneself._init_model_path()self. self._init_model_dir()self. self._init_writer()self. self._init_train_transform()self. self._init_val_transform()self. self._init_vocab()self. self._load_mode_state_dict()self. self._init_data_loader(self.args.train_file_list, self.train_transform)self. self._init_data_loader(self.args.val_file_list, self.val_transform)self. self._init_visual_extractor()self. self._init_mlc()self. self._init_co_attention()self. self._init_sentence_model()self. self._init_word_model()self. self._init_ce_criterion()self. self._init_mse_criterion()self. self._init_optimizer()self. self._init_scheduler()self. self._init_logger()self.writer.write("{}\n".format(self.args))def train(self):for epoch_id in range(self.start_epoch, self.args.epochs):train_tag_loss, train_stop_loss, train_word_loss,  self._epoch_train()val_tag_loss, val_stop_loss, val_word_loss,  self._epoch_val()if self.args.= 'train':self.scheduler.step(train_loss)else:self.scheduler.step(val_loss)self.writer.write("[{} - Epoch {}] train loss:{} - val_loss:{} - lr:{}\n".format(self._get_now(),epoch_id,train_loss,val_loss,self.optimizer.param_groups[0]['lr']))self._save_model(epoch_id,val_loss,val_tag_loss,val_stop_loss,val_word_loss,train_loss)self._log(train_tag_loss,train_stop_loss,train_word_loss,train_loss,val_tag_loss,val_stop_loss,val_word_loss,val_loss,self.optimizer.param_groups[0]['lr'],epoch_id)def _epoch_train(self):raise NotImplementedErrordef _epoch_val(self):raise NotImplementedErrordef _init_train_transform(self):transforms.Compose([transforms.Resize(self.args.resize),transforms.RandomCrop(self.args.crop_size),# transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])return transformdef _init_val_transform(self):transforms.Compose([transforms.Resize((self.args.crop_size, self.args.crop_size)),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])return transformdef _init_model_dir(self):os.path.join(self.args.model_path, self.args.saved_model_name)if not os.path.exists(model_dir):os.makedirs(model_dir)os.path.join(model_dir, self._get_now())if not os.path.exists(model_dir):os.makedirs(model_dir)return model_dirdef _init_vocab(self):with open(self.args.vocab_path, 'rb') as f:pickle.load(f)self.writer.write("Vocab Size:{}\n".format(len(vocab)))return vocabdef _load_mode_state_dict(self):self. 0try:torch.load(self.args.load_model_path)self. model_state['epoch']self.writer.write("[Load Model-{} Succeed!]\n".format(self.args.load_model_path))self.writer.write("Load From Epoch {}\n".format(model_state['epoch']))return model_stateexcept Exception as err:self.writer.write("[Load Model Failed] {}\n".format(err))return Nonedef _init_visual_extractor(self):VisualFeatureExtractor(self.args.visual_model_name,self.args.pretrained)try:torch.load(self.args.load_visual_model_path)model.load_state_dict(model_state['model'])self.writer.write("[Load Visual Extractor Succeed!]\n")except Exception as err:self.writer.write("[Load Model Failed] {}\n".format(err))if not self.args.visual_trained:for i, param in enumerate(model.parameters()):param. Falseelse:if self.params:self.params += list(model.parameters())else:self. list(model.parameters())if self.args.cuda:model.cuda()return modeldef _init_mlc(self):MLC(self.args.classes,self.args.sementic_features_dim,self.extractor.out_features,self.args.k)try:torch.load(self.args.load_mlc_model_path)model.load_state_dict(model_state['model'])self.writer.write("[Load MLC Succeed!]\n")except Exception as err:self.writer.write("[Load MLC Failed {}!]\n".format(err))if not self.args.mlc_trained:for i, param in enumerate(model.parameters()):param. Falseelse:if self.params:self.params += list(model.parameters())else:self. list(model.parameters())if self.args.cuda:model.cuda()return modeldef _init_co_attention(self):CoAttention(self.args.attention_version,self.args.embed_size,self.args.hidden_size,self.extractor.out_features,self.args.k,self.args.momentum)try:torch.load(self.args.load_co_model_path)model.load_state_dict(model_state['model'])self.writer.write("[Load Co-attention Succeed!]\n")except Exception as err:self.writer.write("[Load Co-attention Failed {}!]\n".format(err))if not self.args.co_trained:for i, param in enumerate(model.parameters()):param. Falseelse:if self.params:self.params += list(model.parameters())else:self. list(model.parameters())if self.args.cuda:model.cuda()return modeldef _init_sentence_model(self):raise NotImplementedErrordef _init_word_model(self):raise NotImplementedErrordef _init_data_loader(self, file_list, transform):get_loader(self.args.image_dir,self.args.caption_json,file_list,self.vocab,transform,self.args.batch_size,self.args.s_max,self.args.n_max,True)return data_loader@staticmethoddef _init_ce_criterion():return nn.CrossEntropyLoss(False, False)@staticmethoddef _init_mse_criterion():return nn.MSELoss()def _init_optimizer(self):return torch.optim.Adam(self.params, self.args.learning_rate)def _log(self,train_tags_loss,train_stop_loss,train_word_loss,train_loss,val_tags_loss,val_stop_loss,val_word_loss,val_loss,lr,epoch):'train tags loss': train_tags_loss,'train stop loss': train_stop_loss,'train word loss': train_word_loss,'train loss': train_loss,'val tags loss': val_tags_loss,'val stop loss': val_stop_loss,'val word loss': val_word_loss,'val loss': val_loss,'learning rate': lrfor tag, value in info.items():self.logger.scalar_summary(tag, value, epoch + 1)def _init_logger(self):Logger(os.path.join(self.model_dir, 'logs'))return loggerdef _init_writer(self):open(os.path.join(self.model_dir, 'logs.txt'), 'w')return writerdef _to_var(self, x, True):if self.args.cuda:x.cuda()return Variable(x, requires_grad)def _get_date(self):return str(time.strftime('%Y%m%d', time.gmtime()))def _get_now(self):return str(time.strftime('%Y%m%d-%H:%M', time.gmtime()))def _init_scheduler(self):ReduceLROnPlateau(self.optimizer, 'min', self.args.patience, 0.1)return schedulerdef _init_model_path(self):if not os.path.exists(self.args.model_path):os.makedirs(self.args.model_path)def _init_log_path(self):if not os.path.exists(self.args.log_path):os.makedirs(self.args.log_path)def _save_model(self,epoch_id,val_loss,val_tag_loss,val_stop_loss,val_word_loss,train_loss):def save_whole_model(_filename):self.writer.write("Saved Model in {}\n".format(_filename))torch.save({'extractor': self.extractor.state_dict(),'mlc': self.mlc.state_dict(),'co_attention': self.co_attention.state_dict(),'sentence_model': self.sentence_model.state_dict(),'word_model': self.word_model.state_dict(),'optimizer': self.optimizer.state_dict(),'epoch': epoch_id},os.path.join(self.model_dir, "{}".format(_filename)))def save_part_model(_filename, value):self.writer.write("Saved Model in {}\n".format(_filename))torch.save({"model": value},os.path.join(self.model_dir, "{}".format(_filename)))if val_loss < self.min_val_loss:"val_best_loss.pth.tar"save_whole_model(file_name)self. val_lossif train_loss < self.min_train_loss:"train_best_loss.pth.tar"save_whole_model(file_name)self. train_loss# if val_tag_loss < self.min_val_tag_loss:#     save_part_model("extractor.pth.tar", self.extractor.state_dict())#     save_part_model("mlc.pth.tar", self.mlc.state_dict())#     self. val_tag_loss# if val_stop_loss < self.min_val_stop_loss:#     save_part_model("sentence.pth.tar", self.sentence_model.state_dict())#     self. val_stop_loss# if val_word_loss < self.min_val_word_loss:#     save_part_model("word.pth.tar", self.word_model.state_dict())#     self. val_word_lossclass LSTMDebugger(DebuggerBase):def _init_(self, args):DebuggerBase.__init__(self, args)self. argsdef _epoch_train(self):tag_loss, stop_loss, word_loss,  0, 0, 0, 0self.extractor.train()self.mlc.train()self.co_attention.train()self.sentence_model.train()self.word_model.train()for i, (images, _, label, captions, prob) in enumerate(self.train_data_loader):batch_tag_loss, batch_stop_loss, batch_word_loss,  0, 0, 0, 0self._to_var(images)visual_features,  self.extractor.forward(images)tags,  self.mlc.forward(avg_features)self.mse_criterion(tags, self._to_var(label, False)).sum()Noneself._to_var(torch.zeros(images.shape[0], 1, self.args.hidden_size))self._to_var(torch.Tensor(captions).long(), False)self._to_var(torch.Tensor(prob).long(), False)for sentence_index in range(captions.shape[1]):ctx, _,  self.co_attention.forward(avg_features,semantic_features,prev_hidden_states)topic, p_stop, hidden_states,  self.sentence_model.forward(ctx,prev_hidden_states,sentence_states)batch_stop_loss += self.ce_criterion(p_stop.squeeze(), prob_real[:, sentence_index]).sum()# print("p_stop:{}".format(p_stop.squeeze()))# print("prob_real:{}".format(prob_real[:, sentence_index]))for word_index in range(1, captions.shape[2]):self.word_model.forward(topic, context[:, sentence_index, :word_index])(context[:, sentence_index, word_index] > 0).float()batch_word_loss += (self.ce_criterion(words, context[:, sentence_index, word_index])* word_mask).sum() * (0.9 ** word_index)# batch_word_loss += (self.ce_criterion(words, context[:, sentence_index, word_index])).sum()# print("words:{}".format(torch.max(words, 1)[1]))# print("real:{}".format(context[:, sentence_index, word_index]))self.args.lambda_tag * batch_tag_loss \+ self.args.lambda_stop * batch_stop_loss \+ self.args.lambda_word * batch_word_lossself.optimizer.zero_grad()batch_loss.backward()if self.args.clip > 0:torch.nn.utils.clip_grad_norm(self.sentence_model.parameters(), self.args.clip)torch.nn.utils.clip_grad_norm(self.word_model.parameters(), self.args.clip)self.optimizer.step()tag_loss += self.args.lambda_tag * batch_tag_loss.datastop_loss += self.args.lambda_stop * batch_stop_loss.dataword_loss += self.args.lambda_word * batch_word_loss.dataloss += batch_loss.datareturn tag_loss, stop_loss, word_loss, lossdef _epoch_val(self):tag_loss, stop_loss, word_loss,  0, 0, 0, 0# self.extractor.eval()# self.mlc.eval()# self.co_attention.eval()# self.sentence_model.eval()# self.word_model.eval()# for i, (images, _, label, captions, prob) in enumerate(self.val_data_loader):#     batch_tag_loss, batch_stop_loss, batch_word_loss,  0, 0, 0, 0#      self._to_var(images, False)#     visual_features,  self.extractor.forward(images)#     tags,  self.mlc.forward(avg_features)#      self.mse_criterion(tags, self._to_var(label, False)).sum()#      None#      self._to_var(torch.zeros(images.shape[0], 1, self.args.hidden_size))#      self._to_var(torch.Tensor(captions).long(), False)#      self._to_var(torch.Tensor(prob).long(), False)#     for sentence_index in range(captions.shape[1]):#         ctx, v_att,  self.co_attention.forward(avg_features,#                                                       semantic_features,#                                                       prev_hidden_states)#         topic, p_stop, hidden_states,  self.sentence_model.forward(ctx,#                                                                                     prev_hidden_states,#                                                                                     sentence_states)#         print("p_stop:{}".format(p_stop.squeeze()))#         print("prob_real:{}".format(prob_real[:, sentence_index]))#         batch_stop_loss += self.ce_criterion(p_stop.squeeze(), prob_real[:, sentence_index]).sum()#         for word_index in range(1, captions.shape[2]):#              self.word_model.forward(topic, context[:, sentence_index, :word_index])#              (context[:, sentence_index, word_index] > 0).float()#             batch_word_loss += (self.ce_criterion(words, context[:, sentence_index, word_index])#                                 * word_mask).sum()#             print("words:{}".format(torch.max(words, 1)[1]))#             print("real:{}".format(context[:, sentence_index, word_index]))#      self.args.lambda_tag * batch_tag_loss \#                  + self.args.lambda_stop * batch_stop_loss \#                  + self.args.lambda_word * batch_word_loss#     tag_loss += self.args.lambda_tag * batch_tag_loss.data#     stop_loss += self.args.lambda_stop * batch_stop_loss.data#     word_loss += self.args.lambda_word * batch_word_loss.data#     loss += batch_loss.datareturn tag_loss, stop_loss, word_loss, lossdef _init_sentence_model(self):SentenceLSTM(self.args.sent_version,self.args.embed_size,self.args.hidden_size,self.args.sentence_num_layers,self.args.dropout,self.args.momentum)try:torch.load(self.args.load_sentence_model_path)model.load_state_dict(model_state['model'])self.writer.write("[Load Sentence Model Succeed!\n")except Exception as err:self.writer.write("[Load Sentence model Failed {}!]\n".format(err))if not self.args.sentence_trained:for i, param in enumerate(model.parameters()):param. Falseelse:if self.params:self.params += list(model.parameters())else:self. list(model.parameters())if self.args.cuda:model.cuda()return modeldef _init_word_model(self):WordLSTM(len(self.vocab),self.args.embed_size,self.args.hidden_size,self.args.word_num_layers,self.args.n_max)try:torch.load(self.args.load_word_model_path)model.load_state_dict(model_state['model'])self.writer.write("[Load Word Model Succeed!\n")except Exception as err:self.writer.write("[Load Word model Failed {}!]\n".format(err))if not self.args.word_trained:for i, param in enumerate(model.parameters()):param. Falseelse:if self.params:self.params += list(model.parameters())else:self. list(model.parameters())if self.args.cuda:model.cuda()return modelif = '__main__':import warningswarnings.filterwarnings("ignore")argparse.ArgumentParser()"""Data Argument"""parser.add_argument('--patience', int, 50)parser.add_argument('--mode', str, 'train')# Path Argumentparser.add_argument('--vocab_path', str, './data/new_data/vocab.pkl','the path for vocabulary object')parser.add_argument('--image_dir', str, './data/images','the path for images')parser.add_argument('--caption_json', str, './data/new_data/captions.json','path for captions')parser.add_argument('--train_file_list', str, './data/new_data/train_data.txt','the train array')parser.add_argument('--val_file_list', str, './data/new_data/val_data.txt','the val array')# transforms argumentparser.add_argument('--resize', int, 256,'size for resizing images')parser.add_argument('--crop_size', int, 224,'size for randomly cropping images')# Load/Save model argumentparser.add_argument('--model_path', str, './report_v4_models/','path for saving trained models')parser.add_argument('--load_model_path', str, '','The path of loaded model')parser.add_argument('--saved_model_name', str, 'v4','The name of saved model')"""Model Argument"""parser.add_argument('--momentum', int, 0.1)# VisualFeatureExtractorparser.add_argument('--visual_model_name', str, 'resnet152','CNN model name')parser.add_argument('--pretrained', 'store_true', True,'not using pretrained model when training')parser.add_argument('--load_visual_model_path', str,'.')parser.add_argument('--visual_trained', 'store_true', True,'Whether train visual extractor or not')# MLCparser.add_argument('--classes', int, 210)parser.add_argument('--sementic_features_dim', int, 512)parser.add_argument('--k', int, 10)parser.add_argument('--load_mlc_model_path', str,'.')parser.add_argument('--mlc_trained', 'store_true', True)# Co-Attentionparser.add_argument('--attention_version', str, 'v4')parser.add_argument('--embed_size', int, 512)parser.add_argument('--hidden_size', int, 512)parser.add_argument('--load_co_model_path', str, '.')parser.add_argument('--co_trained', 'store_true', True)# Sentence Modelparser.add_argument('--sent_version', str, 'v1')parser.add_argument('--sentence_num_layers', int, 2)parser.add_argument('--dropout', float, 0)parser.add_argument('--load_sentence_model_path', str,'.')parser.add_argument('--sentence_trained', 'store_true', True)# Word Modelparser.add_argument('--word_num_layers', int, 1)parser.add_argument('--load_word_model_path', str,'.')parser.add_argument('--word_trained', 'store_true', True)"""Training Argument"""parser.add_argument('--batch_size', int, 16)parser.add_argument('--learning_rate', int, 0.001)parser.add_argument('--epochs', int, 1000)parser.add_argument('--clip', float, -1,'gradient clip, -1 means no clip (default: 0.35)')parser.add_argument('--s_max', int, 6)parser.add_argument('--n_max', int, 30)# Loss Functionparser.add_argument('--lambda_tag', float, 10000)parser.add_argument('--lambda_stop', float, 10)parser.add_argument('--lambda_word', float, 1)parser.parse_args()args. torch.cuda.is_available()LSTMDebugger(args)debugger.train()